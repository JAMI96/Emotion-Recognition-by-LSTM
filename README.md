## Speech Emotion Recognition
Aims to develop a system capable of automatically detecting emotions from speech signals.
We start by collecting a dataset of speech samples labeled with corresponding emotions.
Preprocessing techniques are applied to clean and standardize the audio data. Feature extraction methods such as MFCCs capture relevant information from speech signals. ML models, such as SVM, RNN, and CNN, are used. Here, I chose CNN to train on the extracted features to classify emotions. The model is evaluated using metrics like accuracy and F1 score to assess its performance. Finally, we deploy the trained model into real-world applications where it can accurately recognize emotion in a speech in real-time.
